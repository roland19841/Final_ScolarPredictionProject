# ğŸ“ PrÃ©diction de la RÃ©ussite Scolaire â€” Phase dâ€™industrialisation

## ğŸš€ Cas d'usage standard en local

Cette section dÃ©crit **le scÃ©nario de dÃ©monstration standard** permettant de prÃ©senter lâ€™application de bout en bout.

### 1ï¸âƒ£ Lancement de lâ€™application (Docker recommandÃ©)

PrÃ©requis :
- Docker
- Docker Compose

Depuis la racine du projet :

```bash
docker compose up --build
```

Tous les services sont alors dÃ©marrÃ©s automatiquement.

### 2ï¸âƒ£ AccÃ¨s aux interfaces

- **Interface utilisateur (IHM Streamlit)**  
  ğŸ‘‰ http://localhost:8501  

- **API FastAPI (Swagger)**  
  ğŸ‘‰ http://localhost:8000/docs  

- **MLflow (suivi des entraÃ®nements)**  
  ğŸ‘‰ http://localhost:5000  

- **Prometheus (collecte des mÃ©triques)**  
  ğŸ‘‰ http://localhost:9090  

- **Grafana (dashboards & visualisation)**  
  ğŸ‘‰ http://localhost:3000  
  *Identifiants par dÃ©faut (si non modifiÃ©s) :* `admin` / `admin`

- **Uptime Kuma (supervision disponibilitÃ©)**  
  ğŸ‘‰ http://localhost:3001  
---

### 3ï¸âƒ£ VÃ©rification de la santÃ© de lâ€™API

Dans Swagger :
- Appeler `GET /health`
- VÃ©rifier :
  - API active
  - modÃ¨le chargÃ©
  - uptime
  - mÃ©triques du dernier entraÃ®nement

â¡ï¸ Objectif : montrer que lâ€™API est **monitorÃ©e et opÃ©rationnelle**.

---

### 4ï¸âƒ£ EntraÃ®nement du modÃ¨le (endpoint /train)

Dans Swagger :
- Appeler `POST /train`
- (optionnel) spÃ©cifier un chemin de dataset
- Observer :
  - calcul des mÃ©triques
  - sauvegarde du modÃ¨le
  - crÃ©ation dâ€™un run MLflow

Dans MLflow :
- ouvrir le run
- montrer :
  - paramÃ¨tres
  - mÃ©triques
  - artefacts

â¡ï¸ Objectif : dÃ©montrer le **rÃ©entraÃ®nement monitorÃ© et traÃ§able**.

---

### 5ï¸âƒ£ PrÃ©diction via lâ€™IHM

Dans lâ€™IHM Streamlit :
- renseigner les caractÃ©ristiques dâ€™un Ã©lÃ¨ve
- cliquer sur *PrÃ©dire*
- observer :
  - prÃ©diction
  - probabilitÃ© associÃ©e

â¡ï¸ Objectif : montrer lâ€™usage **non technique** du modÃ¨le.

---

### 6ï¸âƒ£ TraÃ§abilitÃ© des prÃ©dictions

Dans le dossier :
```
logs/inference_log.jsonl
```

Montrer quâ€™une ligne est ajoutÃ©e Ã  chaque prÃ©diction :
- inputs
- outputs
- timestamp
- user_id

â¡ï¸ Objectif : dÃ©montrer lâ€™**auditabilitÃ©**.

---

## ğŸ§  PrÃ©sentation gÃ©nÃ©rale du projet

Ce projet propose une **application de machine learning industrialisÃ©e** permettant de prÃ©dire la rÃ©ussite scolaire dâ€™un Ã©lÃ¨ve Ã  partir de caractÃ©ristiques socio-Ã©ducatives (scÃ©nario 3 du dataset *Student Performance*).

Lâ€™objectif nâ€™est pas uniquement de produire un modÃ¨le performant, mais de dÃ©montrer la capacitÃ© Ã  :
- dÃ©ployer un modÃ¨le sous forme de service
- assurer sa traÃ§abilitÃ©
- garantir sa robustesse
- automatiser son cycle de vie

---

## ğŸ§© Architecture globale

La solution repose sur plusieurs composants indÃ©pendants :
- **API FastAPI** : exposition du modÃ¨le, entraÃ®nement, prÃ©diction
- **IHM Streamlit** : interface utilisateur non technique
- **MLflow** : suivi des entraÃ®nements
- **Prometheus / Grafana / Uptime Kuma** : monitoring
- **Docker** : dÃ©ploiement reproductible
- **GitHub Actions** : CI/CD

---

## ğŸ”§ Stack technique

| Couche | Technologie |
|------|------------|
| API | FastAPI |
| IHM | Streamlit |
| ML | scikit-learn |
| Tracking | MLflow |
| Monitoring | Prometheus, Grafana, Uptime Kuma |
| CI/CD | GitHub Actions |
| Conteneurisation | Docker / Docker Compose |
| Langage | Python 3.11 |

---

## ğŸ“‚ Structure du projet

```
SCOLAR_PREDICTION_PROJECT/
â”œâ”€â”€ api_app/                # API FastAPI
â”œâ”€â”€ ihm_app/                # Interface Streamlit
â”œâ”€â”€ artifacts/              # ModÃ¨les et features
â”œâ”€â”€ logs/                   # Logs d'infÃ©rence
â”œâ”€â”€ mlruns/                 # MLflow
â”œâ”€â”€ data/                   # DonnÃ©es CSV
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ README.md
```

---

## ğŸ” Cycle de vie Machine Learning

### EntraÃ®nement
- dÃ©clenchÃ© via `/train`
- validation croisÃ©e
- mÃ©triques sauvegardÃ©es
- modÃ¨le versionnÃ©

### PrÃ©diction
- validation des entrÃ©es
- infÃ©rence
- journalisation automatique

---

## ğŸ“Œ Bonnes pratiques mises en Å“uvre

- sÃ©paration claire API / IHM
- validation des donnÃ©es en plusieurs couches
- versioning (Semantic Versioning)
- CI/CD automatisÃ©e
- monitoring applicatif
- traÃ§abilitÃ© des prÃ©dictions

---

## ğŸ‘¤ Auteur

Roland RENIER - Projet rÃ©alisÃ© dans le cadre dâ€™un **livrable de certification Expert IT / IA**.


